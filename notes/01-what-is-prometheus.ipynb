{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Is Prometheus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Open source, metrics-based monitoring system\n",
    "- It has a simple yet powerful data model and a query language that lets you analyze how applications and infrastucture are performing\n",
    "- It does not try to solve problems outside of the metrics space\n",
    "- It is primarily written in Go\n",
    "- Prometheus' data model identifies each time series not just with a name, but also with an unordered set of key-value pairs called labels.\n",
    "- The PromQL query language allows aggregation across any of these labels, so you can analyse not just per process but also per datacetner and per service or by any other labels that you have defined. **These can be graphed in dashboard systems such as Grafana**. \n",
    "- Alerts can be defined using the exact same PromQL query language that you use for graphing.\n",
    "  - If you can graph it, you can alert on it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Is Monitoring?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most monitoring is about the same thing: events. Events can be almost anything including:\n",
    "\n",
    "- Receiving a HTTP request \n",
    "- Sending a HTTP 400 response \n",
    "- Entering a function \n",
    "- Reaching the else of an if statement \n",
    "- Leaving a function \n",
    "- A user logging in \n",
    "- Writing data to disk \n",
    "- Reading data from the network \n",
    "- Requesting more memory from the kernel\n",
    "\n",
    "As a metric-based monitoring system, Prometheus is designed to track overall system health, behaviour, and performance rather than individual events. Put another way, Prometheus cares that there were 15 requests in the last minute that took 4 seconds to handle, resulted in 40 database calls, 17 cache hits, and 2 purchases by customers. The cost and code paths of the individual calls would be the concern of profiling or logging.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prometheus Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![prometheus-architecture](assets/prometheus-arch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Client Libraries\n",
    "\n",
    "- Metrics do not typically magically spring forth from applications\n",
    "- Someone hast to add the instrumentation that produces tehm\n",
    "- With usually only two or three lines of code, you can both define a metric and add your desired instrumentation inline in code you control. This is referred to as direct instrumentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Not all code you run is code that you can control or even have access to, and thus adding direct instrumentation isn't really an option.\n",
    "- E.g: It's unlikely that operating system kernels will start outputting Prometheus-formatted metrics over to HTTP anytime soon.\n",
    "- Such software often has some interface through which you can access metrics.\n",
    "- An exporter is a piece of software that you deploy right beside the application you want to obtain metrics from.\n",
    "- It takes requests from Prometheus, gathers the required data from the application, transforms them into the correct format, and finally returns them in a response to Prometheus. In other words, an exporter is like a small one-to-one proxy, converting data between the metrics interface of an application and the prometheus exposition format. \n",
    "- Unlike the direct instrumentation, exporters use  a different sytle of instrumentation known as **custom collectors** or **ConstMetrics**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service Discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Once you have all your applications instrumented and your exporters running, Prometheus needs to know where they are.\n",
    "- Prometheus has integrations with many common service discovery mechanisms such as Kubernetes, EC2, Consul, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Service discovery and relabelling give us a list of targets to be monitored.\n",
    "- Now Prometheus needs to fetch the metrics.\n",
    "- Prometheus does this by sending a HTTP request called **a scrape**\n",
    "- The response to the scrape is parsed and ingested into storage\n",
    "- Several useful metrics are also added in, such as if the scrape succeeded and how long it took.\n",
    "- Scrapes happen regularly; usually you would configure it to happen every 10 to 60 seconds for each target.\n",
    "\n",
    "\n",
    "**NOTE**: Prometheus is a pull-based system. It decides when and what to scrape, based on its configuration. There are also push-based systems, where the monitoring target decides if it is going to be monitored and how often."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prometheus stores data locally in a custom database.\n",
    "- Distributed systems are challenging to make reliable, so Prometheus does not attempt to do any form of clustering\n",
    "- The storage system can handle ingestion millions of samples per second, making it possible to monitor thousands of machines with a single Prometheus server.\n",
    "- The compression algorithms used can achieve 1.3 bytes per sample on real-world data.\n",
    "- **An SSD is recommended, but not strictly required**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dashboards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prometheus has a number of HTTP APIs that allow you to both request raw data and evaluate PromQL queries.\n",
    "- These can be used to produce graphs and dashboards.\n",
    "- Out of the box, Prometheus provides the **expression** browser.\n",
    "- It uses these APIs and is suitable for ad hoc querying and data exploration, but it is not a general dashboard system.\n",
    "- It is recommended that you use Grafana for dashboards. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alerts\n",
    "\n",
    "- Aggregating metrics from thousands of machines on the fly everytime you render a graph can get a little laggy.\n",
    "- Recording rules allow PromQL expressions to be evaluated on a regular basis and their results ingested into the storage engine\n",
    "- Alerting rules are another form of recording rules.\n",
    "- Alerts are sent to the Alertmanager."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alert management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Alertmanager receives alerts from Prometheus servers and turns them into notifications. \n",
    "- Notifications can include email, chat applications such as Slack and services such as PagerDuty.\n",
    "- The Alertmanager does more than blindly turn alerts into notifications on a one-to-one basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Prometheus Is Not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Promotheus is not suitable for storing event logs or individual events.\n",
    "- Nor is it the best choice for high cardinality data, such as email addresses or usernames\n",
    "- Prometheus is designed for operational monitoring, where small inaccuracies and race conditions due to factors like kernel scheduling and failed scrapes are a fact of life."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
